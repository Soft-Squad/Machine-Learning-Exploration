{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95bfc67c",
   "metadata": {},
   "source": [
    "## Winters, Alexander (V00970263)\n",
    "\n",
    "# Problem 7. Old-Growth Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7bcee9",
   "metadata": {},
   "source": [
    "### Sources:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb70d3f",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "\n",
    "https://www.kdnuggets.com/2022/02/random-forest-decision-tree-key-differences.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47634f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86eb4039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "654be02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, zero_one_loss\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53142cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['votes', 'unemployment', 'med_hh_inc', 'per_capita_inc',\n",
       "       'poverty_all_ages', 'deep_pov_all', 'deep_pov_children', 'population',\n",
       "       'total_area', 'pop_density', 'total_male', 'total_female',\n",
       "       'voter_turnout', 'democrat', 'county', 'state', 'education', 'religion',\n",
       "       'age_young', 'age_adult', 'age_old', 'ethnic_male', 'ethnic_female'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elections_df = pd.read_csv('elections_clean.csv')\n",
    "elections_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84e50952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the label vector\n",
    "label_vector = elections_df.pop('democrat')\n",
    "\n",
    "# Take only the categorial features\n",
    "categorial_features = ['education', 'religion', 'ethnic_male', 'ethnic_female']\n",
    "\n",
    "# We only want the categorial features and our label vector\n",
    "elections_df = elections_df[categorial_features]\n",
    "# One-hot encoding of the categorial_features\n",
    "elections_df = pd.get_dummies(elections_df, categorial_features)\n",
    "elections_df['democrat'] = label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65b2eac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy of the Decision-Tree: 87.82371649250341 %\n",
      "The training error of the Decision-Tree: 12.176283507496588 %\n",
      "\n",
      "The validation accuracy of the Decision-Tree: 88.77118644067797 %\n",
      "The validation error of the Decision-Tree: 11.228813559322038 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data 70/30\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(elections_df.drop('democrat', axis=1), elections_df['democrat'], train_size=0.7)\n",
    "# Generate random forest\n",
    "RForest = RandomForestClassifier(n_estimators=50, max_depth=3, criterion='entropy')\n",
    "# Train random forest\n",
    "RForest.fit(X_train, Y_train)\n",
    "\n",
    "# Train and Test prediction\n",
    "train_prediction = RForest.predict(X_train)\n",
    "test_prediction = RForest.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and error for training and testing data\n",
    "train_acc = accuracy_score(Y_train, train_prediction) * 100\n",
    "train_err = zero_one_loss(Y_train, train_prediction) * 100\n",
    "\n",
    "test_acc = accuracy_score(Y_test, test_prediction) * 100\n",
    "test_err = zero_one_loss(Y_test, test_prediction) * 100\n",
    "\n",
    "print(\"The training accuracy of the Decision-Tree: \" + str(train_acc) + \" %\")\n",
    "print(\"The training error of the Decision-Tree: \" + str(train_err) + \" %\\n\")\n",
    "\n",
    "print(\"The validation accuracy of the Decision-Tree: \" + str(test_acc) + \" %\")\n",
    "print(\"The validation error of the Decision-Tree: \" + str(test_err) + \" %\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d2259",
   "metadata": {},
   "source": [
    "Unsurprisingly, the Random-Forest accuracy is higher (~89%) than my Decision-Tree (~88%). However, the difference is only ~1%. It is hard to come to any complete conclusions, but generally, Random-Forests have inceased accuracy because they elegantly solve overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfd8c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
